{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color='green'>Person wise feature extraction</font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions for different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import variation\n",
    "from scipy import stats\n",
    "from astropy.stats import median_absolute_deviation\n",
    "from statsmodels import robust\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "def mad(A):\n",
    "    return robust.mad(A)\n",
    "\n",
    "def trim(result):\n",
    "    #result=int(0 if result is None else result)\n",
    "    return stats.trim_mean(result,0.1)\n",
    "\n",
    "def RMS(y):\n",
    "    return np.sqrt(np.mean(y**2))\n",
    "\n",
    "class Vectorr(object):\n",
    "\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "    def __abs__(self):\n",
    "        \n",
    "        return (self.x ** 2 ).sum()   \n",
    "\n",
    "def energy(x):\n",
    "    vector1 = Vectorr(x)\n",
    "    return abs(vector1) \n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "def ent(x):\n",
    "    return stats.entropy(x)\n",
    "\n",
    "def mead(A):\n",
    "    return median_absolute_deviation(A)\n",
    "\n",
    "def iqr(x):\n",
    "    return stats.iqr(x)\n",
    "\n",
    "def sma(x):\n",
    "    return sum(x)/len(x)\n",
    "\n",
    "def cv(A):\n",
    "    var = variation(A, axis=0)\n",
    "    return np.argmax(var)\n",
    "\n",
    "\n",
    "######\n",
    "class Vector(object):\n",
    "\n",
    "    def __init__(self, x, y,z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "    def __abs__(self):\n",
    "        \n",
    "        return (self.x ** 2 + self.y ** 2+self.z ** 2) ** 0.5   \n",
    "\n",
    "def mag(x,y,z):\n",
    "    vector1 = Vector(x, y,z)\n",
    "    return abs(vector1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/kishore/Datasets/PAMAP2_Dataset/cleaned/new/df108.csv')\n",
    "df=df[df.columns[~df.columns.str.contains('magnetometer')]]\n",
    "df=df[df.columns[~df.columns.str.contains('scale16g')]]\n",
    "df=df.drop(columns=['subject','timestamp-s'])\n",
    "act=df['activityID'].unique().tolist()\n",
    "length=len(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "dfd=df\n",
    "magt=pd.DataFrame({'none': []})\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    a=dfd.iloc[:,i]  \n",
    "    b=dfd.iloc[:,i+1] \n",
    "    c=dfd.iloc[:,i+2]\n",
    "    \n",
    "    m=mag(a,b,c)\n",
    "    \n",
    "    m=m.dropna()\n",
    "    \n",
    "    newstr1 = dfd.iloc[:,i].name.replace(\"x\", \"xyzmag\")\n",
    "\n",
    "    neww = pd.DataFrame({newstr1: m})\n",
    "    \n",
    "    magt=pd.concat([magt,neww],axis=1) \n",
    "    \n",
    "    \n",
    "    i+=3\n",
    "    if (i>length-1):\n",
    "        break\n",
    "        \n",
    "magt=magt.drop(columns=['none'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concate datafram with magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df,magt],axis=1)\n",
    "df.columns\n",
    "length=len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select window size of rolling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second= 2276.13\n",
      "minute= 0:37:56.130000\n",
      "window size in second= 1.0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "t=len(df.index)\n",
    "frequency=100\n",
    "t=t/frequency\n",
    "window_size=100\n",
    "percentage_of_everlapping=0.5\n",
    "overlap=window_size*percentage_of_everlapping\n",
    "window_size=int(window_size)\n",
    "overlap=int(overlap)\n",
    "print('second=',t)\n",
    "print(\"minute=\",str(datetime.timedelta(seconds=t)))\n",
    "print(\"window size in second=\",window_size/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=list()\n",
    "feature=pd.DataFrame({'none': []})\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).max()[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "        if (i<2):\n",
    "            for x in se:\n",
    "                label.append(each)\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-max': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "labell=pd.DataFrame({'activityID': label})\n",
    "\n",
    "feature=pd.concat([labell,feature],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=feature.drop(columns=['none'])\n",
    "#feature.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).min()[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-min': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).median()[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-median': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).mean()[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-mean': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).std()[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-std': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).skew()[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-skew': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).kurt()[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-kurt': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# varience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).var()[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-varience': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# root mean square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).apply(RMS,raw=True)[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-rms': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimmed mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).apply(trim,raw=True)[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-trimean': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).apply(energy,raw=True)[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-energy': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# median abs deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).apply(mead,raw=True)[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-mdabsdev': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean abs deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).apply(mad,raw=True)[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-mnabsdev': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correlation coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "dfd=df\n",
    "l=len(df.columns)-len(magt.columns)-1\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    dxy=list()\n",
    "    dxz=list()\n",
    "    dyz=list()\n",
    "    \n",
    "    for each in act:\n",
    "        \n",
    "        a=dfd.iloc[:,i]  \n",
    "        b=dfd.iloc[:,i+1] \n",
    "        c=dfd.iloc[:,i+2]\n",
    "        \n",
    "        a1=dfd.loc[dfd['activityID'] ==each, a.name]\n",
    "        b1=dfd.loc[dfd['activityID'] ==each, b.name]\n",
    "        c1=dfd.loc[dfd['activityID'] ==each, c.name]\n",
    "        \n",
    "        a1=a1.to_frame()\n",
    "        b1=b1.to_frame()\n",
    "        c1=c1.to_frame()\n",
    "        \n",
    "        xy=a1[a.name].rolling(window_size).corr(b1[b.name])[::overlap]\n",
    "        xz=a1[a.name].rolling(window_size).corr(c1[c.name])[::overlap]\n",
    "        yz=b1[b.name].rolling(window_size).corr(c1[c.name])[::overlap]\n",
    "        \n",
    "        xy=xy.dropna()\n",
    "        xz=xz.dropna()\n",
    "        yz=yz.dropna()\n",
    "        \n",
    "        sxy=xy.tolist()\n",
    "        sxz=xz.tolist()\n",
    "        syz=yz.tolist()\n",
    "        \n",
    "        dxy=dxy+sxy\n",
    "        dxz=dxz+sxz\n",
    "        dyz=dyz+syz\n",
    "    \n",
    "    newstr1 = dfd.iloc[:,i].name.replace(\"x\", \"xy-corr\")\n",
    "    newstr2 = dfd.iloc[:,i].name.replace(\"x\", \"xz-corr\")\n",
    "    newstr3 = dfd.iloc[:,i].name.replace(\"x\", \"yz-corr\")\n",
    "    newxy = pd.DataFrame({newstr1: dxy})\n",
    "    newxz = pd.DataFrame({newstr2: dxz})\n",
    "    newyz = pd.DataFrame({newstr3: dyz})\n",
    "    feature=pd.concat([feature,newxy,newxz,newyz],axis=1) \n",
    "    \n",
    "    \n",
    "    i+=3\n",
    "    if (i>l):\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interquartile range(25,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).apply(iqr,raw=True)[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-iqr': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal magnitude area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd=df\n",
    "\n",
    "i=1\n",
    "l=len(df.columns)-len(magt.columns)-1\n",
    "while(True):\n",
    "\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        \n",
    "        a=dfd.iloc[:,i]  \n",
    "        b=dfd.iloc[:,i+1] \n",
    "        c=dfd.iloc[:,i+2]\n",
    "        \n",
    "        a1=dfd.loc[dfd['activityID'] ==each, a.name]\n",
    "        b1=dfd.loc[dfd['activityID'] ==each, b.name]\n",
    "        c1=dfd.loc[dfd['activityID'] ==each, c.name]\n",
    "        \n",
    "        x=a1.rolling(window_size).apply(sma,raw=True)[::overlap]\n",
    "        y=b1.rolling(window_size).apply(sma,raw=True)[::overlap]\n",
    "        z=c1.rolling(window_size).apply(sma,raw=True)[::overlap]\n",
    "\n",
    "        x=x.dropna().tolist()\n",
    "        y=y.dropna().tolist()\n",
    "        z=z.dropna().tolist()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        w=[sum(t) for t in zip(x,y,z)]\n",
    "        \n",
    "        d=d+w\n",
    "\n",
    "     \n",
    "    newstr1 = dfd.iloc[:,i].name.replace(\"x\", \"xyzsma\")    \n",
    "    neww = pd.DataFrame({newstr1: d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "    \n",
    "    i+=3\n",
    "    if(i>l):\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,length):\n",
    "    df1=df.iloc[:,0:i+2:i]\n",
    "    colname = df1.columns[1]\n",
    "    d=list()\n",
    "   \n",
    "    for each in act:\n",
    "        data=df1.loc[df1['activityID'] == each,colname]\n",
    "        new=data.rolling(window_size).cov()[::overlap]\n",
    "        new=new.dropna()\n",
    "        #se=se.append(new,ignore_index=True)\n",
    "        se=new.tolist()\n",
    "        d=d+se\n",
    "     \n",
    "        \n",
    "    neww = pd.DataFrame({colname+'-cov': d})\n",
    "    feature=pd.concat([feature,neww],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4537, 385)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dfa=feature\n",
    "dfa=dfa.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "z=dfa.columns[dfa.isna().any()].tolist()\n",
    "al=feature.columns.tolist()\n",
    "\n",
    "\n",
    "with open('listOfFeature.txt', 'w') as f:\n",
    "    for item in al:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4537, 386)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa=[8]*feature.shape[0]\n",
    "ass=pd.DataFrame({'subject': pa})\n",
    "feature=pd.concat([feature,ass],axis=1)\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4537, 386)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.to_csv (r'/home/kishore/Datasets/PAMAP2_Dataset/cleaned/new/feature1.csv', index = None, header=True)\n",
    "feature=pd.read_csv('/home/kishore/Datasets/PAMAP2_Dataset/cleaned/new/feature8.csv')\n",
    "#feature.shape\n",
    "#feature=feature[feature.columns[~feature.columns.str.contains('cv')]]\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
